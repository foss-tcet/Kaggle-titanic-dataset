{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "   PassengerId  Pclass                                          Name     Sex  \\\n",
      "0          892       3                              Kelly, Mr. James    male   \n",
      "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
      "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
      "3          895       3                              Wirz, Mr. Albert    male   \n",
      "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
      "\n",
      "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
      "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
      "1  47.0      1      0   363272   7.0000   NaN        S  \n",
      "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
      "3  27.0      0      0   315154   8.6625   NaN        S  \n",
      "4  22.0      1      1  3101298  12.2875   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "#Step 1: Load test.csv and train.csv\n",
    "import pandas as pd\n",
    "#Load train.csv\n",
    "tr_url = \"https://storage.googleapis.com/kaggle-competitions-data/kaggle/3136/train.csv?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1514683831&Signature=MMjwcVhnoF2QiFlFlpA88nwSykIbl%2FFdqE%2Bodi8y8oJjTC75rOWtmPnX1KrlUY%2Bl%2FjlosfZ5Wq6aGsOtLkm47ythlR4ybzn51MV6n5buxkInY5fyKVDmXk9Q%2BR3OOiM7hdbEv%2FFuNjuzPhR3CZMM3ATWw7vntkJYns0gmKC72zvJBfR%2BOEAV4EQO6ghRc39guJ49yv9lrr5ToWoGEfnzq45GdoFTosnTSQExfQApHJBMgq0Wy90JaQkym68McR%2BeLgO2%2BOa3RRuXBW0b8KuMI65bExZpiE%2FeyDivJP4o%2FoheBRGRsSRKxgwH0KAtxMoN8oRrC0pRusdb7WE8VqVm9Q%3D%3D\"\n",
    "train = pd.read_csv(tr_url)\n",
    "#Load test.csv\n",
    "te_url = \"https://storage.googleapis.com/kaggle-competitions-data/kaggle/3136/test.csv?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1514683854&Signature=kWvkVcJWry6aPuMmqWhXwX7yKr9CbR6NJ1RkceOtOhwn1lTmSsi1ZW%2B6xeDNtCHebj5gqPaEHqMgvI72Vqc785cFSwVifCi6LVouztTHQ7MmHU1OdvRxHJemNuUPANHHoTAhNB35bbwaQvx31WaI2DG8q4Xj2Ng2x74uSAcPfv0%2BiCLNi6BW6z%2FYQKbWADJH4PvJe0TLX2QL9bXMxRbBH1xcTh9knkN6aRc0Bz9Gr0IPbC2YBWsOYaYyo3HOOfLAI4D5tqtnR2Vev60pijz9Az3KOUwAR17d32S4WONRIGEcMfBrT8ybrw28N3ACNvXEITm9S5M9m3tgwm3ZNAO3lQ%3D%3D\"\n",
    "test = pd.read_csv(te_url)\n",
    "#print train.head() and test.head()\n",
    "print(train.head())\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n",
      "(891, 12)\n",
      "       PassengerId      Pclass         Age       SibSp       Parch        Fare\n",
      "count   418.000000  418.000000  332.000000  418.000000  418.000000  417.000000\n",
      "mean   1100.500000    2.265550   30.272590    0.447368    0.392344   35.627188\n",
      "std     120.810458    0.841838   14.181209    0.896760    0.981429   55.907576\n",
      "min     892.000000    1.000000    0.170000    0.000000    0.000000    0.000000\n",
      "25%     996.250000    1.000000   21.000000    0.000000    0.000000    7.895800\n",
      "50%    1100.500000    3.000000   27.000000    0.000000    0.000000   14.454200\n",
      "75%    1204.750000    3.000000   39.000000    1.000000    0.000000   31.500000\n",
      "max    1309.000000    3.000000   76.000000    8.000000    9.000000  512.329200\n",
      "(418, 11)\n"
     ]
    }
   ],
   "source": [
    "#Step 2: Using .describe() method which  summarizes the columns/features of the DataFrame, including the count of observations, mean, max and so on.\n",
    "\n",
    "#train.describe()\n",
    "print(train.describe())\n",
    "#train.shape\n",
    "print(train.shape)\n",
    "\n",
    "#test.describe()\n",
    "print(test.describe())\n",
    "#test.shape\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    549\n",
      "1    342\n",
      "Name: Survived, dtype: int64\n",
      "0    61.616162\n",
      "1    38.383838\n",
      "Name: Survived, dtype: float64\n",
      "0    468\n",
      "1    109\n",
      "Name: Survived, dtype: int64\n",
      "0    81.109185\n",
      "1    18.890815\n",
      "Name: Survived, dtype: float64\n",
      "1    233\n",
      "0     81\n",
      "Name: Survived, dtype: int64\n",
      "1    74.203822\n",
      "0    25.796178\n",
      "Name: Survived, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Step 3: Female Survived vs Male Survived\n",
    "#.value_counts() method for a two-way comparison on the number of males and females that survived\n",
    "\n",
    "#Passengers Survived vs Passed away in absolute numbers\n",
    "print(train[\"Survived\"].value_counts())\n",
    "\n",
    "#Passengers Survived vs Passed away in percentage\n",
    "t1 = (train[\"Survived\"].value_counts(normalize = True)) * 100\n",
    "print(t1)\n",
    "\n",
    "#Male Passengers Survived vs Passed away in absolute numbers\n",
    "print(train[\"Survived\"][train[\"Sex\"] == 'male'].value_counts())\n",
    "\n",
    "#Male Passengers Survived vs Passed away in percentage\n",
    "t2 = (train[\"Survived\"][train[\"Sex\"] == 'male'].value_counts(normalize = True)) * 100\n",
    "print(t2)\n",
    "\n",
    "#Female Passengers Survived vs Passed away in absolute numbers\n",
    "print(train[\"Survived\"][train[\"Sex\"] == 'female'].value_counts())\n",
    "\n",
    "#Female Passengers Survived vs Passed away in percentage\n",
    "t3 = (train[\"Survived\"][train[\"Sex\"] == 'female'].value_counts(normalize = True)) * 100\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    53.982301\n",
      "0    46.017699\n",
      "Name: Survived, dtype: float64\n",
      "0    61.896839\n",
      "1    38.103161\n",
      "Name: Survived, dtype: float64\n",
      "0      0.0\n",
      "1      0.0\n",
      "2      0.0\n",
      "3      0.0\n",
      "4      0.0\n",
      "5      NaN\n",
      "6      0.0\n",
      "7      1.0\n",
      "8      0.0\n",
      "9      1.0\n",
      "10     1.0\n",
      "11     0.0\n",
      "12     0.0\n",
      "13     0.0\n",
      "14     1.0\n",
      "15     0.0\n",
      "16     1.0\n",
      "17     NaN\n",
      "18     0.0\n",
      "19     NaN\n",
      "20     0.0\n",
      "21     0.0\n",
      "22     1.0\n",
      "23     0.0\n",
      "24     1.0\n",
      "25     0.0\n",
      "26     NaN\n",
      "27     0.0\n",
      "28     NaN\n",
      "29     NaN\n",
      "      ... \n",
      "861    0.0\n",
      "862    0.0\n",
      "863    NaN\n",
      "864    0.0\n",
      "865    0.0\n",
      "866    0.0\n",
      "867    0.0\n",
      "868    NaN\n",
      "869    1.0\n",
      "870    0.0\n",
      "871    0.0\n",
      "872    0.0\n",
      "873    0.0\n",
      "874    0.0\n",
      "875    1.0\n",
      "876    0.0\n",
      "877    0.0\n",
      "878    NaN\n",
      "879    0.0\n",
      "880    0.0\n",
      "881    0.0\n",
      "882    0.0\n",
      "883    0.0\n",
      "884    0.0\n",
      "885    0.0\n",
      "886    0.0\n",
      "887    0.0\n",
      "888    NaN\n",
      "889    0.0\n",
      "890    0.0\n",
      "Name: Child, Length: 891, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Step 4: Age factor for survival since it's probable that children were saved first.\n",
    "\n",
    "#Create new column Child\n",
    "train[\"Child\"] = float('NaN')\n",
    "\n",
    "#Assign 1 to Age of passenger <18 for others assign 0\n",
    "train[\"Child\"][train[\"Age\"] < 18] = 1\n",
    "train[\"Child\"][train[\"Age\"] >= 18] = 0\n",
    "\n",
    "#Print Percentage Survival rate for Age <18 and >=18\n",
    "t4 = (train[\"Survived\"][train[\"Child\"] == 1].value_counts(normalize = True)) * 100\n",
    "print(t4)\n",
    "\n",
    "t5 = (train[\"Survived\"][train[\"Child\"] == 0].value_counts(normalize = True)) * 100\n",
    "print(t5)\n",
    "\n",
    "#Print Child Column\n",
    "print(train[\"Child\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "1      1\n",
      "2      0\n",
      "3      0\n",
      "4      1\n",
      "5      0\n",
      "6      1\n",
      "7      0\n",
      "8      1\n",
      "9      0\n",
      "10     0\n",
      "11     0\n",
      "12     1\n",
      "13     0\n",
      "14     1\n",
      "15     1\n",
      "16     0\n",
      "17     0\n",
      "18     1\n",
      "19     1\n",
      "20     0\n",
      "21     0\n",
      "22     1\n",
      "23     0\n",
      "24     1\n",
      "25     0\n",
      "26     1\n",
      "27     0\n",
      "28     0\n",
      "29     0\n",
      "      ..\n",
      "388    0\n",
      "389    0\n",
      "390    0\n",
      "391    1\n",
      "392    0\n",
      "393    0\n",
      "394    0\n",
      "395    1\n",
      "396    0\n",
      "397    1\n",
      "398    0\n",
      "399    0\n",
      "400    1\n",
      "401    0\n",
      "402    1\n",
      "403    0\n",
      "404    0\n",
      "405    0\n",
      "406    0\n",
      "407    0\n",
      "408    1\n",
      "409    1\n",
      "410    1\n",
      "411    1\n",
      "412    1\n",
      "413    0\n",
      "414    1\n",
      "415    0\n",
      "416    0\n",
      "417    0\n",
      "Name: Survived, Length: 418, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Step5:Create a copy of test as test_copy add a column of Survived in it this is our first prediction for survival\n",
    "test_copy = test\n",
    "\n",
    "#initialize survived to 0\n",
    "test_copy[\"Survived\"] = 0\n",
    "\n",
    "#Set survived to 1 if Sex=='female'\n",
    "test_copy[\"Survived\"][test_copy[\"Sex\"] == 'female'] = 1\n",
    "print(test_copy[\"Survived\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Step6:Using Decision trees importing numpy package and tree from sklearn\n",
    "# Import the Numpy library\n",
    "import numpy as np\n",
    "# Import 'tree' from scikit-learn library\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      0\n",
      "5      0\n",
      "6      0\n",
      "7      0\n",
      "8      1\n",
      "9      1\n",
      "10     1\n",
      "11     1\n",
      "12     0\n",
      "13     0\n",
      "14     1\n",
      "15     1\n",
      "16     0\n",
      "17     0\n",
      "18     1\n",
      "19     1\n",
      "20     0\n",
      "21     0\n",
      "22     1\n",
      "23     0\n",
      "24     1\n",
      "25     1\n",
      "26     0\n",
      "27     0\n",
      "28     1\n",
      "29     0\n",
      "      ..\n",
      "861    0\n",
      "862    1\n",
      "863    1\n",
      "864    0\n",
      "865    1\n",
      "866    1\n",
      "867    0\n",
      "868    0\n",
      "869    0\n",
      "870    0\n",
      "871    1\n",
      "872    0\n",
      "873    0\n",
      "874    1\n",
      "875    1\n",
      "876    0\n",
      "877    0\n",
      "878    0\n",
      "879    1\n",
      "880    1\n",
      "881    0\n",
      "882    1\n",
      "883    0\n",
      "884    0\n",
      "885    1\n",
      "886    0\n",
      "887    1\n",
      "888    1\n",
      "889    0\n",
      "890    0\n",
      "Name: Sex, Length: 891, dtype: object\n",
      "0      0\n",
      "1      1\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "5      2\n",
      "6      0\n",
      "7      0\n",
      "8      0\n",
      "9      1\n",
      "10     0\n",
      "11     0\n",
      "12     0\n",
      "13     0\n",
      "14     0\n",
      "15     0\n",
      "16     2\n",
      "17     0\n",
      "18     0\n",
      "19     1\n",
      "20     0\n",
      "21     0\n",
      "22     2\n",
      "23     0\n",
      "24     0\n",
      "25     0\n",
      "26     1\n",
      "27     0\n",
      "28     2\n",
      "29     0\n",
      "      ..\n",
      "861    0\n",
      "862    0\n",
      "863    0\n",
      "864    0\n",
      "865    0\n",
      "866    1\n",
      "867    0\n",
      "868    0\n",
      "869    0\n",
      "870    0\n",
      "871    0\n",
      "872    0\n",
      "873    0\n",
      "874    1\n",
      "875    1\n",
      "876    0\n",
      "877    0\n",
      "878    0\n",
      "879    1\n",
      "880    0\n",
      "881    0\n",
      "882    0\n",
      "883    0\n",
      "884    0\n",
      "885    2\n",
      "886    0\n",
      "887    0\n",
      "888    0\n",
      "889    1\n",
      "890    2\n",
      "Name: Embarked, Length: 891, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Step7:Cleaning & Formatting Data\n",
    "#Sex and Embarked variables are categorical but in a non-numeric format. Thus, we will need to assign each class a unique integer so that Python can handle the information. Embarked also has some missing values which you should impute witht the most common class of embarkation, which is \"S\".\n",
    "\n",
    "#Male & Female group to integer\n",
    "train[\"Sex\"][train[\"Sex\"] == \"male\"] = 0\n",
    "train[\"Sex\"][train[\"Sex\"] == \"female\"] = 1\n",
    "\n",
    "#Imputing missing embark value with \"S\".\n",
    "train[\"Embarked\"] = train[\"Embarked\"].fillna('S')\n",
    "\n",
    "# Convert the Embarked classes to integer form\n",
    "train[\"Embarked\"][train[\"Embarked\"] == \"S\"] = 0\n",
    "train[\"Embarked\"][train[\"Embarked\"] == \"C\"] = 1\n",
    "train[\"Embarked\"][train[\"Embarked\"] == \"Q\"] = 2\n",
    "\n",
    "#Print the Sex and Embarked columns\n",
    "print(train[\"Sex\"])\n",
    "print(train[\"Embarked\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1 0 0 0 0 1 1 1 1 0 0 0 1 0 1 0 1 0 1 1 1 0 1 0 0 1 0 0 1 1 0 0 0 1\n",
      " 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 1 1 0 1 1 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0\n",
      " 1 0 0 0 1 1 0 1 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 1 0\n",
      " 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 1 1 0 0 1 0 1 1 1 1 0 0 1 0 0 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 1 0 1 0 1 0\n",
      " 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 1 1\n",
      " 1 0 1 0 0 0 0 0 1 1 1 0 1 1 0 1 1 0 0 0 1 0 0 0 1 0 0 1 0 1 1 1 1 0 0 0 0\n",
      " 0 0 1 1 1 1 0 1 0 1 1 1 0 1 1 1 0 0 0 1 1 0 1 1 0 0 1 1 0 1 0 1 1 1 1 0 0\n",
      " 0 1 0 0 1 1 0 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1\n",
      " 1 0 0 0 0 1 1 0 0 0 1 1 0 1 0 0 0 1 0 1 1 1 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 1 1 1 0 0 1 0 1 0 0 1 0 0 1\n",
      " 1 1 1 1 1 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0\n",
      " 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 1 0\n",
      " 1 0 1 0 0 1 0 0 1 0 0 0 1 0 0 1 0 1 0 1 0 1 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1\n",
      " 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0 0 1 0 1 0 0 0 1\n",
      " 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 0 1 0 0 1 0 0 1 1 0 0 0 0 1 0\n",
      " 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 1 1 0 1 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0\n",
      " 0 0 0 1 1 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0\n",
      " 0 0 0 1 1 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0\n",
      " 1 0 1 0 1 0 0 1 0 0 1 1 0 0 1 1 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 1 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 1 1 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 1 0 1 1 1 1 0 0 0 1 0 0 1 1 0 0 1 0 1 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 1\n",
      " 0 1 0]\n",
      "[[3 0 22.0 7.25]\n",
      " [1 1 38.0 71.2833]\n",
      " [3 1 26.0 7.925]\n",
      " ..., \n",
      " [3 1 28.0 23.45]\n",
      " [1 0 26.0 30.0]\n",
      " [3 0 32.0 7.75]]\n",
      "[ 0.12063997  0.31274009  0.22341291  0.34320703]\n",
      "0.977553310887\n"
     ]
    }
   ],
   "source": [
    "#Step 8:First Decision Tree\n",
    "#Using scikit-learn and numpy libraries,scikit-learn can be used to create tree objects from the DecisionTreeClassifier class and numpy arrays as inputs and therefore we will need to create those from the DataFrame that we already have.\n",
    "\n",
    "#fill nan with median age\n",
    "train[\"Age\"] = train[\"Age\"].fillna(train[\"Age\"].median())\n",
    "\n",
    "#target and features\n",
    "#target: A 1D numpy array containing the target from the train data. (Survival in this case)\n",
    "#features: A multidimensional numpy array containing the features/predictors from the train data. (ex. Sex, Age)\n",
    "target = train[\"Survived\"].values\n",
    "features = train[[\"Pclass\", \"Sex\", \"Age\", \"Fare\"]].values\n",
    "\n",
    "#print target and features(optional)\n",
    "print(target)\n",
    "print(features)\n",
    "\n",
    "#Fitting Decision tree\n",
    "my_tree = tree.DecisionTreeClassifier()\n",
    "my_tree = my_tree.fit(features, target)\n",
    "\n",
    "#importance and score of the included features using .feature_importances_ and .score()(to compute mean accuracy)\n",
    "print(my_tree.feature_importances_)\n",
    "print(my_tree.score(features, target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#After Step 8 we come to know that Passenger Fare is the most imp feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 0 34.5 7.8292]\n",
      " [3 1 47.0 7.0]\n",
      " [2 0 62.0 9.6875]\n",
      " ..., \n",
      " [3 0 38.5 7.25]\n",
      " [3 0 27.0 8.05]\n",
      " [3 0 27.0 22.3583]]\n",
      "[0 0 1 1 1 0 0 0 1 0 0 0 1 1 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 0 0 0 1 0 1 0 0\n",
      " 0 0 1 0 1 0 1 1 0 0 0 1 1 1 0 1 1 1 0 0 0 1 1 0 0 0 1 1 0 1 0 0 1 1 0 0 0\n",
      " 1 0 0 1 0 1 1 0 0 0 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 0 1 0 0 0 1 0 0 0 1 0 0\n",
      " 0 1 1 1 0 1 1 0 1 1 0 1 0 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 1 0\n",
      " 1 0 1 0 0 1 0 0 1 1 0 1 1 1 1 1 0 1 1 0 0 0 0 1 0 1 0 1 1 0 1 1 0 1 1 0 1\n",
      " 0 1 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 1 1 0 1 0 0 1 0 1 0 1 0\n",
      " 1 1 1 0 0 1 0 0 0 1 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 1 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1\n",
      " 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 1 0 0 0 1 0 1 0 0 1 0 1 1 1 1 0 0 0 1 0\n",
      " 0 1 0 0 1 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 1 1 0 0 0\n",
      " 0 1 1 1 1 0 0 1 0 0 0]\n",
      "      Survived\n",
      "892          0\n",
      "893          0\n",
      "894          1\n",
      "895          1\n",
      "896          1\n",
      "897          0\n",
      "898          0\n",
      "899          0\n",
      "900          1\n",
      "901          0\n",
      "902          0\n",
      "903          0\n",
      "904          1\n",
      "905          1\n",
      "906          1\n",
      "907          1\n",
      "908          0\n",
      "909          1\n",
      "910          1\n",
      "911          0\n",
      "912          0\n",
      "913          1\n",
      "914          1\n",
      "915          1\n",
      "916          1\n",
      "917          0\n",
      "918          1\n",
      "919          1\n",
      "920          1\n",
      "921          0\n",
      "...        ...\n",
      "1280         0\n",
      "1281         0\n",
      "1282         0\n",
      "1283         1\n",
      "1284         1\n",
      "1285         0\n",
      "1286         0\n",
      "1287         1\n",
      "1288         0\n",
      "1289         1\n",
      "1290         0\n",
      "1291         0\n",
      "1292         1\n",
      "1293         0\n",
      "1294         1\n",
      "1295         1\n",
      "1296         0\n",
      "1297         0\n",
      "1298         0\n",
      "1299         0\n",
      "1300         1\n",
      "1301         1\n",
      "1302         1\n",
      "1303         1\n",
      "1304         0\n",
      "1305         0\n",
      "1306         1\n",
      "1307         0\n",
      "1308         0\n",
      "1309         0\n",
      "\n",
      "[418 rows x 1 columns]\n",
      "(418, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "#Step 9: Predict and Submit to Kaggle\n",
    "#First, you make use of the .predict() method. You provide it the model (my_tree), the values of features from the dataset for which predictions need to be made (test). To extract the features we will need to create a numpy array in the same way as we did when training the model. However, we need to take care of a small but important problem first. There is a missing value in the Fare feature that needs to be imputed.\n",
    "\n",
    "#Male & Female group to integer\n",
    "test[\"Sex\"][test[\"Sex\"] == \"male\"] = 0\n",
    "test[\"Sex\"][test[\"Sex\"] == \"female\"] = 1\n",
    "\n",
    "#fill nan with median age\n",
    "test[\"Age\"] = test[\"Age\"].fillna(test[\"Age\"].median())\n",
    "\n",
    "#impute missing fare value\n",
    "test.Fare[152] = test.Fare.median()\n",
    "\n",
    "#Extract features from test as we did from train\n",
    "test_features = test[[\"Pclass\", \"Sex\", \"Age\", \"Fare\"]].values\n",
    "print(test_features)\n",
    "#Make predictions\n",
    "my_prediction = my_tree.predict(test_features)\n",
    "print(my_prediction)\n",
    "\n",
    "#Next, you need to make sure your output is in line with the submission requirements of Kaggle: a csv file with exactly 418 entries and two columns: PassengerId and Survived. Then use the code provided to make a new data frame using DataFrame(), and create a csv file using to_csv() method from Pandas.\n",
    "PassengerId =np.array(test[\"PassengerId\"]).astype(int)\n",
    "my_solution = pd.DataFrame(my_prediction, PassengerId, columns = [\"Survived\"])\n",
    "print(my_solution)\n",
    "\n",
    "# Check that your data frame has 418 entries\n",
    "print(my_solution.shape)\n",
    "\n",
    "# Write your solution to a csv file with the name my_solution.csv\n",
    "my_solution.to_csv(\"my_solution_one.csv\", index_label = [\"PassengerId\"])\n",
    "\n",
    "#Great! You just created your first decision tree. Download your csv file, and submit the created csv to Kaggle to see the result of your effort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#After Submitting the above solution on kaggle my score was 56% so to improve it we perform overfitting,feature engineering and apply random forests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.905723905724\n"
     ]
    }
   ],
   "source": [
    "#Overfitting: Good performance on the training data, poor generliazation to new data.\n",
    "#Control overfitting by setting \"max_depth\" and \"min_samples_split\"\n",
    "#The max_depth parameter determines when the splitting up of the decision tree stops.\n",
    "#The min_samples_split parameter monitors the amount of observations in a bucket. If a certain threshold is not reached (e.g minimum 10 passengers) no further splitting can be done.\n",
    "\n",
    "#create features_one with some added features\n",
    "features_one = train[[\"Pclass\",\"Age\",\"Sex\",\"Fare\", \"SibSp\",\"Parch\" ,\"Embarked\"]].values\n",
    "\n",
    "#\"max_depth\" and \"min_samples_split\"\n",
    "max_depth = 10\n",
    "min_samples_split = 5\n",
    "my_tree_one = tree.DecisionTreeClassifier(max_depth = 10, min_samples_split = 5, random_state = 1)\n",
    "my_tree_one = my_tree_one.fit(features_one,target)\n",
    "\n",
    "#Print the score of the new decison tree\n",
    "print(my_tree_one.score(features_one,target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.979797979798\n"
     ]
    }
   ],
   "source": [
    "#Feature Engineering\n",
    "#here we add a extra column \"family_size\" to the train data which is a new feature and combination of \"SibSp\" and \"Parch\" plus one(the observation itself)\n",
    "\n",
    "#Create train_two\n",
    "train_two = train.copy()\n",
    "\n",
    "#Now add \"family_size\" column to train_two\n",
    "train_two[\"family_size\"] = train[\"SibSp\"] + train[\"Parch\"] + 1\n",
    "\n",
    "#Add the feature \"family_size\"\n",
    "features_two = train_two[[\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"SibSp\", \"Parch\", \"family_size\"]].values\n",
    "\n",
    "# Define the tree classifier, then fit the model\n",
    "my_tree_two = tree.DecisionTreeClassifier()\n",
    "my_tree_two = my_tree_two.fit(features_two,target)\n",
    "\n",
    "# Print the score of this decision tree\n",
    "print(my_tree_two.score(features_two, target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.939393939394\n",
      "418\n",
      "      Survived\n",
      "892          0\n",
      "893          0\n",
      "894          0\n",
      "895          0\n",
      "896          0\n",
      "897          0\n",
      "898          0\n",
      "899          0\n",
      "900          1\n",
      "901          0\n",
      "902          0\n",
      "903          0\n",
      "904          1\n",
      "905          0\n",
      "906          1\n",
      "907          1\n",
      "908          0\n",
      "909          0\n",
      "910          0\n",
      "911          0\n",
      "912          1\n",
      "913          0\n",
      "914          1\n",
      "915          1\n",
      "916          1\n",
      "917          0\n",
      "918          1\n",
      "919          0\n",
      "920          0\n",
      "921          0\n",
      "...        ...\n",
      "1280         0\n",
      "1281         0\n",
      "1282         0\n",
      "1283         1\n",
      "1284         0\n",
      "1285         0\n",
      "1286         0\n",
      "1287         1\n",
      "1288         0\n",
      "1289         1\n",
      "1290         0\n",
      "1291         0\n",
      "1292         1\n",
      "1293         0\n",
      "1294         1\n",
      "1295         0\n",
      "1296         0\n",
      "1297         0\n",
      "1298         0\n",
      "1299         0\n",
      "1300         1\n",
      "1301         1\n",
      "1302         1\n",
      "1303         1\n",
      "1304         0\n",
      "1305         0\n",
      "1306         1\n",
      "1307         0\n",
      "1308         0\n",
      "1309         1\n",
      "\n",
      "[418 rows x 1 columns]\n",
      "(418, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#Random Forest:if you have trained 3 trees with 2 saying a passenger in the test set will survive and 1 says he will not, the passenger will be classified as a survivor\n",
    "\n",
    "# Import the `RandomForestClassifier`\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# We want the Pclass, Age, Sex, Fare,SibSp, Parch, and Embarked variables\n",
    "features_forest = train[[\"Pclass\", \"Age\", \"Sex\", \"Fare\", \"SibSp\", \"Parch\", \"Embarked\"]].values\n",
    "\n",
    "# Building and fitting my_forest\n",
    "forest = RandomForestClassifier(max_depth = 10, min_samples_split=2, n_estimators = 100, random_state = 1)\n",
    "my_forest = forest.fit(features_forest, target)\n",
    "\n",
    "# Print the score of the fitted random forest\n",
    "print(my_forest.score(features_forest, target))\n",
    "\n",
    "test[\"Embarked\"][test[\"Embarked\"] == \"S\"] = 0\n",
    "test[\"Embarked\"][test[\"Embarked\"] == \"C\"] = 1\n",
    "test[\"Embarked\"][test[\"Embarked\"] == \"Q\"] = 2\n",
    "\n",
    "\n",
    "# Compute predictions on our test set features then print the length of the prediction vector\n",
    "test_features = test[[\"Pclass\", \"Age\", \"Sex\", \"Fare\", \"SibSp\", \"Parch\", \"Embarked\"]].values\n",
    "pred_forest = my_forest.predict(test_features)\n",
    "print(len(pred_forest))\n",
    "#print(test_features)\n",
    "\n",
    "\n",
    "PassengerId =np.array(test[\"PassengerId\"]).astype(int)\n",
    "my_solution1 = pd.DataFrame(pred_forest, PassengerId, columns = [\"Survived\"])\n",
    "print(my_solution1)\n",
    "\n",
    "# Check that your data frame has 418 entries\n",
    "print(my_solution1.shape)\n",
    "\n",
    "# Write your solution to a csv file with the name my_solution.csv\n",
    "my_solution1.to_csv(\"my_solution_four.csv\", index_label = [\"PassengerId\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
